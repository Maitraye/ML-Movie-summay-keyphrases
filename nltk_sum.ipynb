{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "movie_list = []\n",
    "with open(\"movie_dict_3.json\", \"r\") as fin:\n",
    "    for i, line in enumerate(fin):\n",
    "        plot_dict = {}\n",
    "        movie_json = json.loads(line)\n",
    "        plot_dict['imdb_id'] = movie_json['imdb_id']\n",
    "        plot_dict['summary'] = movie_json['Plot']\n",
    "        movie_list.append(plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14820"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "import heapq\n",
    "\n",
    "output_movie_list = []\n",
    "for entry in movie_list:\n",
    "    filename = \"/Users/maitrayedas/Documents/Fall 2018/ML/project/movie/MPST/final_plots_wiki_imdb_combined/raw/\" + entry['imdb_id'] + \".txt\"\n",
    "    with open(filename, \"r\") as fin:\n",
    "        synopsis = fin.read()\n",
    "    \n",
    "    # Removing special characters and digits\n",
    "    formatted_synopsis = re.sub('[^a-zA-Z]', ' ', synopsis )  \n",
    "    formatted_synopsis = re.sub(r'\\s+', ' ', formatted_synopsis)\n",
    "    \n",
    "    #tokenize sentence i.e., find sentences from the synopsis\n",
    "    sentence_list = nltk.sent_tokenize(synopsis) \n",
    "    \n",
    "    #remove stopwords and find word frequencies\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(formatted_synopsis):  \n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    #find weighted frequency\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "       \n",
    "    #calculating sentence frequency\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "  \n",
    "    #retrieve top 7 sentences with the highest scores\n",
    "    summary_sentences = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    entry['out_summary'] = summary\n",
    "    output_movie_list.append(entry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14820"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with Avg\n",
      "True\n",
      "False\n",
      "\trouge-1:\tP: 36.31\tR: 30.80\tF1: 31.31\n",
      "\trouge-2:\tP:  9.90\tR:  4.70\tF1:  6.09\n",
      "\trouge-3:\tP:  7.61\tR:  2.86\tF1:  4.14\n",
      "\trouge-4:\tP:  7.08\tR:  2.58\tF1:  3.79\n",
      "\trouge-l:\tP: 25.63\tR: 21.53\tF1: 22.29\n",
      "\trouge-w:\tP: 13.96\tR:  3.98\tF1:  5.74\n",
      "\n",
      "Evaluation with Best\n",
      "False\n",
      "True\n",
      "\trouge-1:\tP: 36.31\tR: 30.80\tF1: 31.31\n",
      "\trouge-2:\tP:  9.90\tR:  4.70\tF1:  6.09\n",
      "\trouge-3:\tP:  7.61\tR:  2.86\tF1:  4.14\n",
      "\trouge-4:\tP:  7.08\tR:  2.58\tF1:  3.79\n",
      "\trouge-l:\tP: 25.63\tR: 21.53\tF1: 22.29\n",
      "\trouge-w:\tP: 13.96\tR:  3.98\tF1:  5.74\n",
      "\n",
      "Evaluation with Individual\n",
      "False\n",
      "False\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-1:\tP: 11.94\tR: 21.62\tF1: 15.38\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-1:\tP: 91.06\tR: 33.73\tF1: 49.23\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-1:\tP: 49.06\tR: 28.11\tF1: 35.74\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-1:\tP: 27.27\tR: 40.74\tF1: 32.67\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-1:\tP: 28.57\tR: 29.01\tF1: 28.79\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-1:\tP: 38.06\tR: 26.15\tF1: 31.00\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-1:\tP: 25.42\tR: 32.61\tF1: 28.57\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-1:\tP: 27.56\tR: 42.68\tF1: 33.49\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-1:\tP: 28.83\tR: 25.60\tF1: 27.12\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-1:\tP: 35.34\tR: 27.70\tF1: 31.06\n",
      "\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-2:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-2:\tP: 78.69\tR: 29.00\tF1: 42.38\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-2:\tP:  3.81\tR:  2.17\tF1:  2.77\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-2:\tP:  0.83\tR:  1.25\tF1:  1.00\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-2:\tP:  0.76\tR:  0.77\tF1:  0.76\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-2:\tP:  3.76\tR:  2.58\tF1:  3.06\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-2:\tP:  0.85\tR:  1.10\tF1:  0.96\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-2:\tP:  2.38\tR:  3.70\tF1:  2.90\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-2:\tP:  1.82\tR:  1.61\tF1:  1.71\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-2:\tP:  6.09\tR:  4.76\tF1:  5.34\n",
      "\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-3:\tP: 74.38\tR: 27.27\tF1: 39.91\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-3:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-3:\tP:  1.75\tR:  1.37\tF1:  1.54\n",
      "\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-4:\tP: 70.83\tR: 25.84\tF1: 37.86\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-l:\tP: 11.50\tR: 18.86\tF1: 14.29\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-l:\tP: 79.22\tR: 34.63\tF1: 48.19\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-l:\tP: 26.97\tR: 16.96\tF1: 20.82\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-l:\tP: 17.56\tR: 24.53\tF1: 20.46\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-l:\tP: 18.01\tR: 18.24\tF1: 18.12\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-l:\tP: 21.34\tR: 15.61\tF1: 18.03\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-l:\tP: 17.93\tR: 22.06\tF1: 19.78\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-l:\tP: 16.86\tR: 24.28\tF1: 19.90\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-l:\tP: 20.94\tR: 18.96\tF1: 19.90\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-l:\tP: 25.97\tR: 21.19\tF1: 23.34\n",
      "\n",
      "\tHypothesis #0 & Reference #0: \n",
      "\t\trouge-w:\tP:  5.21\tR:  3.99\tF1:  4.52\n",
      "\tHypothesis #1 & Reference #0: \n",
      "\t\trouge-w:\tP: 57.26\tR:  6.64\tF1: 11.91\n",
      "\tHypothesis #2 & Reference #0: \n",
      "\t\trouge-w:\tP: 13.16\tR:  2.65\tF1:  4.42\n",
      "\tHypothesis #3 & Reference #0: \n",
      "\t\trouge-w:\tP:  8.02\tR:  4.98\tF1:  6.14\n",
      "\tHypothesis #4 & Reference #0: \n",
      "\t\trouge-w:\tP:  8.09\tR:  3.10\tF1:  4.48\n",
      "\tHypothesis #5 & Reference #0: \n",
      "\t\trouge-w:\tP:  9.66\tR:  2.31\tF1:  3.73\n",
      "\tHypothesis #6 & Reference #0: \n",
      "\t\trouge-w:\tP:  8.09\tR:  4.20\tF1:  5.53\n",
      "\tHypothesis #7 & Reference #0: \n",
      "\t\trouge-w:\tP:  7.77\tR:  4.98\tF1:  6.07\n",
      "\tHypothesis #8 & Reference #0: \n",
      "\t\trouge-w:\tP:  9.97\tR:  3.37\tF1:  5.04\n",
      "\tHypothesis #9 & Reference #0: \n",
      "\t\trouge-w:\tP: 12.39\tR:  3.57\tF1:  5.55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "for aggregator in ['Avg', 'Best', 'Individual']:\n",
    "    print('Evaluation with {}'.format(aggregator))\n",
    "    apply_avg = aggregator == 'Avg'\n",
    "    apply_best = aggregator == 'Best'\n",
    "\n",
    "    print(apply_avg)\n",
    "    print(apply_best)\n",
    "    evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                           max_n=4,\n",
    "                           limit_length=False,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=apply_avg,\n",
    "                           apply_best=apply_best,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "    \n",
    "    all_hypothesis = []\n",
    "    all_references = []\n",
    "    for entry in output_movie_list:\n",
    "        all_hypothesis.append(entry['out_summary'])\n",
    "        all_references.append(entry['summary'])\n",
    "\n",
    "    scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "\n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
    "            for hypothesis_id, results_per_ref in enumerate(results):\n",
    "                nb_references = len(results_per_ref['p'])\n",
    "                for reference_id in range(nb_references):\n",
    "                    print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
    "                    print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
    "            print()\n",
    "        else:\n",
    "            print(prepare_results(results['p'], results['r'], results['f']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 25.32\tR: 34.90\tF1: 26.61\n",
      "\trouge-2:\tP:  3.97\tR:  4.90\tF1:  3.93\n",
      "\trouge-3:\tP:  1.24\tR:  1.30\tF1:  1.10\n",
      "\trouge-4:\tP:  0.75\tR:  0.68\tF1:  0.61\n",
      "\trouge-l:\tP: 18.40\tR: 25.69\tF1: 19.80\n",
      "\trouge-w:\tP:  9.04\tR:  6.49\tF1:  6.25\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                           max_n=4,\n",
    "                           limit_length=False,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=True,\n",
    "                           apply_best=False,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n",
    "all_hypothesis = []\n",
    "all_references = []\n",
    "for entry in output_movie_list:\n",
    "    all_hypothesis.append(entry['out_summary'])\n",
    "    all_references.append(entry['summary'])\n",
    "\n",
    "scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "textteaser_movie_list = []\n",
    "with open(\"output_textteaser.json\", \"r\")as fin:\n",
    "    for line in fin:\n",
    "        movie_json = json.loads(line)\n",
    "        textteaser_movie_list.append(movie_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14820\n"
     ]
    }
   ],
   "source": [
    "print(len(textteaser_movie_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imdb_id': 'tt1441395',\n",
       " 'out_summary': 'She seems confused and scared, and in the struggle he not only rips her clothes but also her skin, to find she has another black skin underneath. The man from the club stares in shock as the empty skin of the first victim gruesomely floats away. The empty skin floats aimlessly in the black void, twisting like a plastic bag in the wind. Suddenly a sharp snap noise punctuates the silence, and the first victim POPS like a balloon- his skin stretching out and then shrivelling up, just like a popped balloon would. Something she has done has caused the motorcycle man to be displeased, causing him to somehow question or lecture her actions.',\n",
       " 'summary': 'An alien entity inhabits the earthly form of a young woman who combs the roads and streets of Scotland in search of the human prey she came to plunder. She seduces her isolated and forsaken male victims into an otherworldly dimension where they are stripped and consumed. However, existence in all its complexity begin to change the alien visitor. She begins to discover herself as human with tragic and terrifying consequences.',\n",
       " 'title': 'Under the Skin'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textteaser_movie_list[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 26.51\tR: 33.66\tF1: 26.71\n",
      "\trouge-2:\tP:  4.41\tR:  5.17\tF1:  4.23\n",
      "\trouge-3:\tP:  1.43\tR:  1.52\tF1:  1.27\n",
      "\trouge-4:\tP:  0.84\tR:  0.80\tF1:  0.69\n",
      "\trouge-l:\tP: 19.45\tR: 25.25\tF1: 20.20\n",
      "\trouge-w:\tP:  9.78\tR:  6.44\tF1:  6.39\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                           max_n=4,\n",
    "                           limit_length=False,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=True,\n",
    "                           apply_best=False,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n",
    "all_hypothesis = []\n",
    "all_references = []\n",
    "for entry in textteaser_movie_list:\n",
    "    all_hypothesis.append(entry['out_summary'])\n",
    "    all_references.append(entry['summary'])\n",
    "\n",
    "scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
